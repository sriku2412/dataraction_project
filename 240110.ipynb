{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['python', 'sql']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spaCy NLP model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define a function to extract keywords from a resume text\n",
    "def extract_keywords(resume_text):\n",
    "    # Process the resume text using spaCy\n",
    "    doc = nlp(resume_text)\n",
    "    \n",
    "    # Initialize a list to store keywords\n",
    "    keywords = []\n",
    "    \n",
    "    # Define keywords you want to extract\n",
    "    target_keywords = [\"python\", \"sql\", \"data analysis\", \"machine learning\"]\n",
    "    \n",
    "    # Iterate through the tokens in the processed text\n",
    "    for token in doc:\n",
    "        # Check if the token text is in the list of target keywords\n",
    "        if token.text.lower() in target_keywords:\n",
    "            keywords.append(token.text.lower())\n",
    "    \n",
    "    return keywords\n",
    "\n",
    "# Example usage\n",
    "resume_text = \"I am proficient in Python and SQL, and I have experience in data analysis and machine learning.\"\n",
    "keywords = extract_keywords(resume_text)\n",
    "print(keywords)  # This will print: ['python', 'sql', 'data analysis', 'machine learning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.122*\"topic\" + 0.119*\"finance\" + 0.115*\"risk\" + 0.114*\"management\" + 0.113*\"business\"')\n",
      "(1, '0.130*\"text\" + 0.117*\"data\" + 0.114*\"analytics\" + 0.111*\"modeling\" + 0.109*\"business\"')\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "# Create a list of documents (each document is a list of words)\n",
    "documents = [[\"data\", \"analytics\", \"topic\", \"modeling\", \"text\"],\n",
    "             [\"business\", \"finance\", \"risk\", \"management\"],\n",
    "             # Add more documents as needed\n",
    "            ]\n",
    "\n",
    "# Create a dictionary and corpus\n",
    "dictionary = corpora.Dictionary(documents)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in documents]\n",
    "\n",
    "# Build the LDA model\n",
    "lda_model = models.LdaModel(corpus, num_topics=2, id2word=dictionary)\n",
    "\n",
    "# Print the topics and their associated words\n",
    "topics = lda_model.print_topics(num_topics=2, num_words=5)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from flask import Flask\n",
    "\n",
    "# app = Flask(__name__)\n",
    "\n",
    "# @app.route('/')\n",
    "# def hello_world():\n",
    "#     return 'Hello, World!'\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>organization_name</th>\n",
       "      <th>title</th>\n",
       "      <th>locations</th>\n",
       "      <th>organization_topics</th>\n",
       "      <th>organization_industry_tags</th>\n",
       "      <th>url</th>\n",
       "      <th>has_description</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Vidyard</td>\n",
       "      <td>Director of Sales, Enterprise Acquisition</td>\n",
       "      <td>['United States', 'Canada', 'Remote']</td>\n",
       "      <td>['B2B', 'Media &amp; entertainment', 'Productivity...</td>\n",
       "      <td>['Media', 'Software']</td>\n",
       "      <td>https://www1.communitech.ca/companies/vidyard/...</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;div data-testid=\"careerPage\"&gt;&lt;p&gt;At Vidyard, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Hootsuite</td>\n",
       "      <td>Senior Software Developer | Développeur logici...</td>\n",
       "      <td>['Toronto, ON, Canada', 'Vancouver, BC, Canada']</td>\n",
       "      <td>['500+', 'Advertising/marketing', 'B2B', 'Soft...</td>\n",
       "      <td>['Information Technology', 'Media', 'Sales and...</td>\n",
       "      <td>https://www1.communitech.ca/companies/hootsuit...</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;div data-testid=\"careerPage\"&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Semios</td>\n",
       "      <td>Chemistry Co-op</td>\n",
       "      <td>['Vancouver, BC, Canada']</td>\n",
       "      <td>['Agriculture', 'B2B', 'C100 alumni', 'Data &amp; ...</td>\n",
       "      <td>['Agriculture and Farming']</td>\n",
       "      <td>https://www1.communitech.ca/companies/semios/j...</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;div data-testid=\"careerPage\"&gt;&lt;p&gt;&lt;strong&gt;Who w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Axonify</td>\n",
       "      <td>Senior Talent Acquisition Partner (15 months c...</td>\n",
       "      <td>['Toronto, ON, Canada', 'Waterloo, ON, Canada']</td>\n",
       "      <td>['B2B', 'Data &amp; analytics', 'Education', 'Fema...</td>\n",
       "      <td>['Education', 'Information Technology', 'Softw...</td>\n",
       "      <td>https://www1.communitech.ca/companies/axonify/...</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;div data-testid=\"careerPage\"&gt;&lt;section&gt;&lt;div&gt;Ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Deep Genomics</td>\n",
       "      <td>(Senior) Research Scientist - Statistical Gene...</td>\n",
       "      <td>['Toronto, ON, Canada']</td>\n",
       "      <td>['50-99', 'AI/ML', 'B2B', 'Biotechnology', 'Me...</td>\n",
       "      <td>['Biotechnology', 'DeepTech', 'Health', 'Softw...</td>\n",
       "      <td>https://www1.communitech.ca/companies/deep-gen...</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;div data-testid=\"careerPage\"&gt;&lt;section&gt;&lt;div&gt;&lt;b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 organization_name  \\\n",
       "0           1           Vidyard   \n",
       "1           2         Hootsuite   \n",
       "2           3            Semios   \n",
       "3           4           Axonify   \n",
       "4           5     Deep Genomics   \n",
       "\n",
       "                                               title  \\\n",
       "0          Director of Sales, Enterprise Acquisition   \n",
       "1  Senior Software Developer | Développeur logici...   \n",
       "2                                    Chemistry Co-op   \n",
       "3  Senior Talent Acquisition Partner (15 months c...   \n",
       "4  (Senior) Research Scientist - Statistical Gene...   \n",
       "\n",
       "                                          locations  \\\n",
       "0             ['United States', 'Canada', 'Remote']   \n",
       "1  ['Toronto, ON, Canada', 'Vancouver, BC, Canada']   \n",
       "2                         ['Vancouver, BC, Canada']   \n",
       "3   ['Toronto, ON, Canada', 'Waterloo, ON, Canada']   \n",
       "4                           ['Toronto, ON, Canada']   \n",
       "\n",
       "                                 organization_topics  \\\n",
       "0  ['B2B', 'Media & entertainment', 'Productivity...   \n",
       "1  ['500+', 'Advertising/marketing', 'B2B', 'Soft...   \n",
       "2  ['Agriculture', 'B2B', 'C100 alumni', 'Data & ...   \n",
       "3  ['B2B', 'Data & analytics', 'Education', 'Fema...   \n",
       "4  ['50-99', 'AI/ML', 'B2B', 'Biotechnology', 'Me...   \n",
       "\n",
       "                          organization_industry_tags  \\\n",
       "0                              ['Media', 'Software']   \n",
       "1  ['Information Technology', 'Media', 'Sales and...   \n",
       "2                        ['Agriculture and Farming']   \n",
       "3  ['Education', 'Information Technology', 'Softw...   \n",
       "4  ['Biotechnology', 'DeepTech', 'Health', 'Softw...   \n",
       "\n",
       "                                                 url  has_description  \\\n",
       "0  https://www1.communitech.ca/companies/vidyard/...             True   \n",
       "1  https://www1.communitech.ca/companies/hootsuit...             True   \n",
       "2  https://www1.communitech.ca/companies/semios/j...             True   \n",
       "3  https://www1.communitech.ca/companies/axonify/...             True   \n",
       "4  https://www1.communitech.ca/companies/deep-gen...             True   \n",
       "\n",
       "                                         description  \n",
       "0  <div data-testid=\"careerPage\"><p>At Vidyard, w...  \n",
       "1  <div data-testid=\"careerPage\"><p><span><em><st...  \n",
       "2  <div data-testid=\"careerPage\"><p><strong>Who w...  \n",
       "3  <div data-testid=\"careerPage\"><section><div>Ax...  \n",
       "4  <div data-testid=\"careerPage\"><section><div><b...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume = pd.read_csv(r\"C:\\Users\\srika\\OneDrive\\Documents\\York\\Sem-2 york\\MBAN 6090 - Analytics Consulting Project\\webscrape\\communitech\\resume_data_231230.csv\")\n",
    "jobs = pd.read_csv(r\"C:\\Users\\srika\\OneDrive\\Documents\\York\\Sem-2 york\\MBAN 6090 - Analytics Consulting Project\\webscrape\\communitech\\jobs_info.csv\")\n",
    "jobs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Raw_html</th>\n",
       "      <th>Resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>software engineer of iot cloud</td>\n",
       "      <td>&lt;div class=\"document fontsize fontface vmargin...</td>\n",
       "      <td>Jessica Claire Montgomery Street , San Francis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>senior software engineer</td>\n",
       "      <td>&lt;div class=\"document fontsize fontface vmargin...</td>\n",
       "      <td>Jessica Claire Montgomery Street , San Francis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>software engineer</td>\n",
       "      <td>&lt;div class=\"document fontsize fontface vmargin...</td>\n",
       "      <td>Jessica Claire Montgomery Street , San Francis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>senior software engineer</td>\n",
       "      <td>&lt;div class=\"document fontsize fontface vmargin...</td>\n",
       "      <td>Jessica Claire Montgomery Street , San Francis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.net developer</td>\n",
       "      <td>&lt;div class=\"document fontsize fontface vmargin...</td>\n",
       "      <td>Jessica Claire Montgomery Street , San Francis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6196</th>\n",
       "      <td>engineering manager/quality manager</td>\n",
       "      <td>&lt;div class=\"document fontsize fontface vmargin...</td>\n",
       "      <td>Jessica Claire Montgomery Street , San Francis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6197</th>\n",
       "      <td>engineering and maintenance manager</td>\n",
       "      <td>&lt;div class=\"document fontsize fontface vmargin...</td>\n",
       "      <td>Jessica Claire Montgomery Street , San Francis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6198</th>\n",
       "      <td>advantage coordinator/marketing</td>\n",
       "      <td>&lt;div class=\"document fontsize fontface vmargin...</td>\n",
       "      <td>Jessica Claire Montgomery Street , San Francis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6199</th>\n",
       "      <td>customer experience alternative delivery manager</td>\n",
       "      <td>&lt;div class=\"document fontsize fontface vmargin...</td>\n",
       "      <td>Jessica Claire , , 609 Johnson Ave. , 49204 , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6200</th>\n",
       "      <td>assistant customer experience manager</td>\n",
       "      <td>&lt;div class=\"document fontsize fontface vmargin...</td>\n",
       "      <td>Jessica Claire resumesample@example.com (555) ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6201 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  \\\n",
       "0                       software engineer of iot cloud   \n",
       "1                             senior software engineer   \n",
       "2                                    software engineer   \n",
       "3                             senior software engineer   \n",
       "4                                       .net developer   \n",
       "...                                                ...   \n",
       "6196               engineering manager/quality manager   \n",
       "6197               engineering and maintenance manager   \n",
       "6198                   advantage coordinator/marketing   \n",
       "6199  customer experience alternative delivery manager   \n",
       "6200             assistant customer experience manager   \n",
       "\n",
       "                                               Raw_html  \\\n",
       "0     <div class=\"document fontsize fontface vmargin...   \n",
       "1     <div class=\"document fontsize fontface vmargin...   \n",
       "2     <div class=\"document fontsize fontface vmargin...   \n",
       "3     <div class=\"document fontsize fontface vmargin...   \n",
       "4     <div class=\"document fontsize fontface vmargin...   \n",
       "...                                                 ...   \n",
       "6196  <div class=\"document fontsize fontface vmargin...   \n",
       "6197  <div class=\"document fontsize fontface vmargin...   \n",
       "6198  <div class=\"document fontsize fontface vmargin...   \n",
       "6199  <div class=\"document fontsize fontface vmargin...   \n",
       "6200  <div class=\"document fontsize fontface vmargin...   \n",
       "\n",
       "                                                 Resume  \n",
       "0     Jessica Claire Montgomery Street , San Francis...  \n",
       "1     Jessica Claire Montgomery Street , San Francis...  \n",
       "2     Jessica Claire Montgomery Street , San Francis...  \n",
       "3     Jessica Claire Montgomery Street , San Francis...  \n",
       "4     Jessica Claire Montgomery Street , San Francis...  \n",
       "...                                                 ...  \n",
       "6196  Jessica Claire Montgomery Street , San Francis...  \n",
       "6197  Jessica Claire Montgomery Street , San Francis...  \n",
       "6198  Jessica Claire Montgomery Street , San Francis...  \n",
       "6199  Jessica Claire , , 609 Johnson Ave. , 49204 , ...  \n",
       "6200  Jessica Claire resumesample@example.com (555) ...  \n",
       "\n",
       "[6201 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Clean and prepare the data\n",
    "    resume['Resume'].fillna('', inplace=True)  # Replace NaN with empty strings\n",
    "    jobs['description'].fillna('', inplace=True)  # Replace NaN with empty strings\n",
    "\n",
    "    # Ensure data is in string format\n",
    "    resume['Resume'] = resume['Resume'].astype(str)\n",
    "    jobs['description'] = jobs['description'].astype(str)\n",
    "\n",
    "    # Create TF-IDF Vectorizer\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "    # Combine all texts for TF-IDF\n",
    "    all_texts = pd.concat([resume['Resume'], jobs['description']])\n",
    "    vectorizer.fit(all_texts)\n",
    "\n",
    "    # Transform each resume and job posting\n",
    "    resumes_tfidf = vectorizer.transform(resume['Resume'])\n",
    "    job_postings_tfidf = vectorizer.transform(jobs['description'])\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    similarity_matrix = cosine_similarity(resumes_tfidf, job_postings_tfidf)\n",
    "\n",
    "    # Process similarity_matrix to find top matches for each resume\n",
    "    # For example, you can loop through each resume and find the top matching job postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with stat\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\srika\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3534: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, render_template_string\n",
    "\n",
    "# Flask app setup\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Assuming similarity_matrix, resume, and jobs are defined elsewhere\n",
    "# Add your definitions or import statements for these variables here\n",
    "\n",
    "# Function to find matching jobs\n",
    "# Function to find matching jobs with descending scores\n",
    "def find_matching_jobs(user_id, page=0, items_per_page=10):\n",
    "    job_matches = similarity_matrix[user_id]\n",
    "    sorted_indices = sorted(range(len(job_matches)), key=lambda i: job_matches[i], reverse=True)\n",
    "    start = page * items_per_page\n",
    "    end = start + items_per_page\n",
    "    top_matches_indices = sorted_indices[start:end]\n",
    "    \n",
    "    # Calculate normalized scores with decreasing values\n",
    "    max_score = max(job_matches) if job_matches else 1\n",
    "    normalized_scores = [round((max_score - job_matches[i]) / max_score * 5, 2) for i in top_matches_indices]\n",
    "    \n",
    "    return list(zip(top_matches_indices, normalized_scores))\n",
    "\n",
    "\n",
    "# Login Functionality\n",
    "username = 'admin'  # Placeholder\n",
    "password = 'admin'  # Placeholder\n",
    "\n",
    "def login(user, pwd):\n",
    "    return user == username and pwd == password\n",
    "\n",
    "# Function to display resumes (modified for Flask)\n",
    "def display_resumes(user_id):\n",
    "    html_output = '<h1>Resumes</h1>'\n",
    "    for index, row in resume.iterrows():\n",
    "        html_output += f\"<p>{row['Title']}: {row['Resume'][:100]}...</p>\"\n",
    "        if index == user_id:\n",
    "            matching_jobs = find_matching_jobs(index)\n",
    "            for job_id, score in matching_jobs:\n",
    "                job_title = jobs.iloc[job_id]['title']\n",
    "                job_description = jobs.iloc[job_id]['description']\n",
    "                first_line_description = job_description.split('.')[0]\n",
    "                html_output += f\"<p>{job_title} (Score: {score}/5): {first_line_description}</p>\"\n",
    "    return render_template_string(html_output)\n",
    "\n",
    "# Route for the home page with login form\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def login_page():\n",
    "    if request.method == 'POST':\n",
    "        user = request.form['username']\n",
    "        pwd = request.form['password']\n",
    "        if login(user, pwd):\n",
    "            return display_resumes(0)  # Replace 0 with actual user_id\n",
    "        else:\n",
    "            return 'Invalid Credentials'\n",
    "    return '''\n",
    "        <form method=\"post\">\n",
    "            Username: <input type=\"text\" name=\"username\"><br>\n",
    "            Password: <input type=\"password\" name=\"password\"><br>\n",
    "            <input type=\"submit\" value=\"Login\">\n",
    "        </form>\n",
    "    '''\n",
    "\n",
    "# Run the Flask app\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "different method :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "resume_df = pd.read_csv(r\"C:\\Users\\srika\\OneDrive\\Documents\\York\\Sem-2 york\\MBAN 6090 - Analytics Consulting Project\\webscrape\\communitech\\resume_data_231230.csv\")\n",
    "jobs_df = pd.read_csv(r\"C:\\Users\\srika\\OneDrive\\Documents\\York\\Sem-2 york\\MBAN 6090 - Analytics Consulting Project\\webscrape\\communitech\\jobs_info.csv\")\n",
    "\n",
    "\n",
    "resume_df['Resume_i'] = resume_df['Resume']\n",
    "jobs_df['description_i'] = jobs_df['description']\n",
    "\n",
    "resume_df['Resume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       <div data-testid=\"careerPage\"><p>At Vidyard, w...\n",
       "1       <div data-testid=\"careerPage\"><p><span><em><st...\n",
       "2       <div data-testid=\"careerPage\"><p><strong>Who w...\n",
       "3       <div data-testid=\"careerPage\"><section><div>Ax...\n",
       "4       <div data-testid=\"careerPage\"><section><div><b...\n",
       "                              ...                        \n",
       "4177    <div data-testid=\"careerPage\"><h2 class=\"uk-he...\n",
       "4178    <div data-testid=\"careerPage\"><div class=\"cont...\n",
       "4179    <div data-testid=\"careerPage\"><section><div>St...\n",
       "4180    <div data-testid=\"careerPage\"><div class=\"cont...\n",
       "4181    <div data-testid=\"careerPage\"><div class=\"cont...\n",
       "Name: description, Length: 4182, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jobs_df['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jessica Claire Montgomery Street , San Francisco , CA 94105 609 Johnson Ave. , 49204 , Tulsa , OK Home: (555) 432-1000 - Cell: - resumesample@example.com - - Summary Diligent Software Engineer offering 4 years in the IT industry with a focus on product design and development. Extensive knowledge of Python and Java . Possess the ability to scale to great extend both in front-end and backend development. Highlights Proficient in Python, Java Hands on experience with NodeJS Scripting - JavaScript, Bash Scripting Databases - MySQL, SQLServer, Oracle10G, MongoDB (NoSQL) Expert in Git Version Control and hands on Git-Flow Experience with \\xa0Apache2.0 web server and Tomcat-7.0 application server. Frameworks: Bootstrap, JQuery Agile development methodologies Self-starter Team player Experience 05/2015 to 03/2016 Full Stack Developer (Intern) State Of Virginia – Buckingham , VA , Developed RESTful API webservices using Java Spring framework. Worked on MongoDb and HBase databases. Used Git for version control and have worked with GitFlow . Contributed \\xa0to \\xa0the Development Android application - https://play.google.com/store/apps/details?id=com.ScanLife. 09/2014 to 04/2015 Student Assistant Programmer Steadymd – Chicago , IL , Academic and Research Computing Systems, New Jersey Institute of Technology. Worked on projects small projects on Linux(SL6) Aided in the setup/upgrade of Kong Nodes for NJIT. 08/2014 to 10/2014 Research Assistant Kas Software Solutions Llc – Pompano Beach , FL , Worked on a Research Project \"Security Learning by Ontology Browsing (SLOB)\" for a short duration. Redesigned the entire java web application in python in a very short span of time Developed an OWL Parser in python to parse OWL files \\xad https://github.com/deeshank/OwlParser . 09/2013 to 07/2014 Software Engineer Cisco India Private Ltd – City , STATE , India Worked with Tools Development & Automation team Developed custom tools for the HCS Solution Testing team to enable them to test VOIP call flows via Real phones as well as Camelots (Virtual endpoints) Developed the testing tool in Python using TNGpi framework and it is currently being used by the teams to test different call flows. Developed the tool using Python Flask framework and Restful web services to run various testcases. 06/2010 to 02/2012 Programmer Analyst Cognizant Technology Solutions – City , STATE , India Worked in Datawarehousing domain as L1 Support Engineer to handle nightly ETL jobs for migrating data from OLTP to OLAP, creating cognos reports, developing ETL mappings for client \\xad Orbitz, U.S. Worked with Informatica 8.1 and SQL Server Intergration Service( SSIS ) for data migration. Developed Python scripts to automate various tasks. Awarded as Raising Star at Cognizant Technology Solutions. Education Expected in 2016 Master of Science : Computer Science New Jersey Institute of Technology - Newark , NJ GPA: GPA: 3.87/4.0 Expected in 2010 Bachelor of Science : Computer Science & Engineering Amrita School of Engineering - Coimbatore , TN GPA: GPA: 7.9/10.0 Skills Java, Springs, Python, Flask, Neo4J, NoSQL, Apache, Tomcat, Web2py, MongoDB, HBase, Android, Gradle, Scripting, Bash, PHP, HTML, CSS, Bootstrap, JQuery, Git, Github, GitFlow, Maven, XML, JSON, BeautifulSoup, REST, RESTAP, Jenkins, Angular JS, Tornado, TNGpi'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resume_df['Resume'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\srika\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\srika\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\srika\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def processing(resume):\n",
    "    # Check if the value is not NaN and is a string\n",
    "    if isinstance(resume, str):\n",
    "        # Preprocessing\n",
    "        resume = resume.lower()\n",
    "        resume = resume.replace('\\n', ' ')\n",
    "        resume = resume.replace('\\t', ' ')\n",
    "        # Tokenization\n",
    "        resume = nltk.word_tokenize(resume)\n",
    "        # Removing stopwords\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        resume = [word for word in resume if word.lower() not in stop_words]\n",
    "        # Stemming\n",
    "        stemmer = PorterStemmer()\n",
    "        resume = [stemmer.stem(word) for word in resume]\n",
    "        # Lemmatization\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        resume = [lemmatizer.lemmatize(word) for word in resume]\n",
    "        # Remove punctuation\n",
    "        resume = [word for word in resume if word not in string.punctuation]\n",
    "\n",
    "        resume = ' '.join(resume)\n",
    "\n",
    "    return resume\n",
    "\n",
    "# Apply the processing function to the 'Resume' column of the DataFrame\n",
    "resume_df['Resume'] = resume_df['Resume'].apply(processing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"jessica clair montgomeri street san francisco ca 94105 609 johnson ave. 49204 tulsa ok h 555 432-1000 c resumesampl example.com date birth india singl summari highli motiv sale associ extens custom servic sale experi outgo sale profession track record drive increas sale improv buy experi elev compani profil target market profession experi softwar engin iot cloud 05/2014 current belveder trade – boulder co china work salesforc iot cloud massiv scalabl event process engin realtim engag analyt main focu design implement cluster provis manag iot cloud 1. provis manag aw heroku resourc heavili involv cloudform ec2 auto-sc elb etc 2. deploy micro-servic manag version upgrad iot platform properli scale scale micro-servic necessari micro-servic support use kafka storm spark cassandra kubernet 3. find best practic store sensit critic inform exampl auth token client secret 4. custom platform busi need dynam involv jessicatabas migrat kafka migrat cloudform infrastructur upjess co-host workload across 10k custom batch transform ~100mm row user jessicata jessicaili real-tim ingest 7 tb event jessicaili ~80 mb/ sustain softwar engin 02/2014 05/2014 locket – citi state locket lock screen app display imag content base interest select googl one `` best app 2014 '' mainli focus backend develop includ intellig content gener display machin learn develop intern 05/2013 08/2013 british broadcast corpor bbc – citi state 1. develop face detect recognit program java implement machin learn algorithm e.g. eigenfac pca fisherfac ljessica 2. appli text mine techniqu subtitl assist facial identif actor tv program 3. achiev 98 accuraci rate stanjessicard face jessicatabas e.g. orl educ master scienc comput statist machin learn expect 2013 univers colleg london london gpa statu bachelor scienc electron commerc comput expect jun 2010 univers liverpool liverpool gpa statu technic skill program java python javascript build tool gradl maven op relat puppet ansibl saltstack docker kubernet jenkin bash other aw hibern postgr\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resume_df['Resume'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remot startup headquart canada build smart curiou driven team ’ make softwar help sale rep sell better.prospect lead gener app help find contact data right insid browser real time best sale team top tech compani worldwid use prospect crush sale targets.about youw current team 15 peopl — 16.you enjoy write beauti code care whether code work think deepli well perform understood futur developers.y like ship thing realiz build excel product marathon sprint regularli make improv iterations.y excel commun realiz work remot requir thought commun great written communication.y self-manag open feedback enjoy take goal figur ship without heavi direct regular check-ins.y product customer-centr whether bug fix perf improv new featur realiz everi line code opportun make user ’ experi better.our engin teamw current team 7 develop role divid base project work on.w work 4-week long develop cycl focu ad new featur fix bug make improv cycl 2-week cool-off use work anyth would like well plan next cycle.our stack current backend java 17 spring cloud aw manag terraform databas aw dynamodb postgresql frontend typescript react intern gitlab launchdarkli linear project work onyou work backend rest api written use modern java practices.thi high-impact role look someon take real ownership one two core featur within six month extrem import part applic serv thousand customers.y work close backend frontend team cto.w priorit project base custom request most.som thing might work includ data scale real-tim data discoveri engin process 5x-10x volum devop speed ci pipelin faster build integr add featur exist integr monitor modern log metric infrastructur report add function allow custom run advanc custom usag report hire processour process follow initi screen 90 min complet asynchron questionnair relev code challeng cto interview 30 min call cto delv experi discus project ’ work live code session 3 hour collabor problem team real-tim founder ’ interview 30 min final convers founder understand person goal share compani vision job offer find 're great fit 'll make offer stage must have 5+ year java program experi experi relat databas familiar spring nice have previou work experi use spring boot similar modern java framework profici modern infrastructur tool terraform experi aw cloud vendor track record build concurr system scale past success work asynchron fulli remot environ demonstr usag metrics-centr approach use tool like grafana ’ getsalari 80,000 90,000 u dollar per yearbenefit 4 week paid time work remot anywher world disrupt almost meet part small team big thing independ flexibl work environ 1,500 annual continu learn budget book cours self-improv 1,000+ annual travel spend allow money spend vacat benefit health dental etc compani hsa peopl live canada\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "def processing_jobs(job):\n",
    "    # Preprocessing\n",
    "    job = str(job)  # Ensure it's a string\n",
    "    job = job.lower()\n",
    "    job = job.replace('\\n', ' ')\n",
    "    job = job.replace('\\t', ' ')\n",
    "    # Remove HTML tags\n",
    "    soup = BeautifulSoup(job, 'html.parser')\n",
    "    job = soup.get_text()\n",
    "    # Tokenization\n",
    "    job = nltk.word_tokenize(job)\n",
    "    # Removing stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    job = [word for word in job if word.lower() not in stop_words]\n",
    "    # Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    job = [stemmer.stem(word) for word in job]\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    job = [lemmatizer.lemmatize(word) for word in job]\n",
    "    # Remove punctuation\n",
    "    job = [word for word in job if word not in string.punctuation]\n",
    "\n",
    "    job = ' '.join(job)\n",
    "\n",
    "    return job\n",
    "\n",
    "jobs_df['description'] = jobs_df['description'].fillna('').apply(processing_jobs)\n",
    "print(jobs_df['description'][82])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
